{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Tutorial: An√°lise de Sentimentos em Portugu√™s com BERT\n",
    "\n",
    "Neste tutorial, vamos aprender como usar o modelo BERT para prever o **sentimento (positivo ou negativo)** de coment√°rios em portugu√™s no IMDB.\n",
    "\n",
    "Utilizaremos o modelo **BERT pr√©-treinado da Hugging Face** (`neuralmind/bert-base-portuguese-cased`) e faremos o fine-tuning com PyTorch.\n",
    "\n",
    "## üìå 1. O que √© o BERT?\n",
    "\n",
    "O **BERT** (Bidirectional Encoder Representations from Transformers) √© um modelo baseado em Transformers, ideal para tarefas de NLP como classifica√ß√£o de texto, an√°lise de sentimentos, entre outros.\n",
    "\n",
    "Neste caso, usamos o **encoder** do BERT para classificar frases como **positivas** ou **negativas**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.env/lib/python3.11/site-packages (2.7.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: transformers in ./.env/lib/python3.11/site-packages (4.53.0)\n",
      "Requirement already satisfied: datasets in ./.env/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./.env/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in ./.env/lib/python3.11/site-packages (2.3.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.2.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tqdm in ./.env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.env/lib/python3.11/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.env/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in ./.env/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.env/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.env/lib/python3.11/site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.env/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.env/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.env/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.env/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.env/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.env/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.env/lib/python3.11/site-packages (from plotly) (1.45.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.env/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.env/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.11/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Downloading torchvision-0.22.1-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.7.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-6.2.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: plotly, torchvision, torchaudio\n",
      "Successfully installed plotly-6.2.0 torchaudio-2.7.1 torchvision-0.22.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio \\\n",
    "    transformers datasets scikit-learn pandas plotly \\\n",
    "    tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade jupyter ipywidgets\n",
    "%jupyter nbextension enable --py widgetsnbextension # removed !pip on the recommendation of a comment.\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "for i in tqdm(range(10)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 2. Carregando os Dados\n",
    "\n",
    "Vamos usar um dataset com resenhas do IMDB traduzidas para portugu√™s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este √© um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever m√∫sicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de lat√£o n√£o √© uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_en  \\\n",
       "id                                                      \n",
       "1   Once again Mr. Costner has dragged out a movie...   \n",
       "2   This is an example of why the majority of acti...   \n",
       "3   First of all I hate those moronic rappers, who...   \n",
       "4   Not even the Beatles could write songs everyon...   \n",
       "5   Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                              text_pt sentiment  \n",
       "id                                                               \n",
       "1   Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "2   Este √© um exemplo do motivo pelo qual a maiori...       neg  \n",
       "3   Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "4   Nem mesmo os Beatles puderam escrever m√∫sicas ...       neg  \n",
       "5   Filmes de fotos de lat√£o n√£o √© uma palavra apr...       neg  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega o dataset\n",
    "data = pd.read_csv(\"dataset/imdb-reviews-pt-br.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Estrutura do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49459 entries, 1 to 49460\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text_en    49459 non-null  object\n",
      " 1   text_pt    49459 non-null  object\n",
      " 2   sentiment  49459 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 3 colunas:\n",
    "\n",
    "* `text_en`: texto original em ingl√™s\n",
    "* `text_pt`: texto traduzido para portugu√™s\n",
    "* `sentiment`: r√≥tulo de sentimento (`pos` ou `neg`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 3. Explorando a Distribui√ß√£o de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts().plot.pie(autopct=\"%.2f\", explode=[0.01, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset est√° **balanceado**, ent√£o podemos usar **acur√°cia** como m√©trica principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ 4. Dividindo os Dados\n",
    "\n",
    "Vamos criar conjuntos de treino, valida√ß√£o (dev) e teste na propor√ß√£o 90/5/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_dev_size = int(0.05 * len(data))\n",
    "train_dev, test = train_test_split(\n",
    "    data, test_size=test_dev_size, stratify=data[\"sentiment\"], random_state=42\n",
    ")\n",
    "train, dev = train_test_split(\n",
    "    train_dev, test_size=test_dev_size, stratify=train_dev[\"sentiment\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ 5. Preparando o Dataset para o BERT\n",
    "\n",
    "Criamos uma classe para tokenizar e estruturar os dados conforme esperado pelo BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImdbPt(Dataset):\n",
    "    def __init__(self, tokenizer, X, y):\n",
    "        tokenized = tokenizer(list(X), truncation=True, max_length=512)\n",
    "        self.samples = [\n",
    "            {**{k: tokenized[k][i] for k in tokenized}, \"labels\": y.iloc[i]}\n",
    "            for i in range(len(X))\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.samples[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßº 6. Tokenizando e Criando Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x32168f100>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gsampaio/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/gsampaio/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "\n",
    "train_dataset = ImdbPt(\n",
    "    tokenizer, train[\"text_pt\"], (train[\"sentiment\"] == \"pos\").astype(int)\n",
    ")\n",
    "dev_dataset = ImdbPt(tokenizer, dev[\"text_pt\"], (dev[\"sentiment\"] == \"pos\").astype(int))\n",
    "test_dataset = ImdbPt(\n",
    "    tokenizer, test[\"text_pt\"], (test[\"sentiment\"] == \"pos\").astype(int)\n",
    ")\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=collator)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=16, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 7. Carregando o Modelo e Configurando o Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"neuralmind/bert-base-portuguese-cased\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Congelando o BERT no in√≠cio\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 8. Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_inputs_to_device(inputs, device):\n",
    "    return {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    tp = tn = fp = fn = 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = send_inputs_to_device(batch, device)\n",
    "            loss, scores = model(**batch)[:2]\n",
    "            losses.append(loss.item())\n",
    "            pred = scores.argmax(dim=1)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            tp += ((pred == 1) & (labels == 1)).sum().item()\n",
    "            tn += ((pred == 0) & (labels == 0)).sum().item()\n",
    "            fp += ((pred == 1) & (labels == 0)).sum().item()\n",
    "            fn += ((pred == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\n",
    "        f\"Dev loss: {sum(losses)/len(losses):.2f}; Acc: {acc:.2f}; tp: {tp}; tn: {tn}; fp: {fp}; fn: {fn}\"\n",
    "    )\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 9. Treinando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m loss_acc = \u001b[32m0\u001b[39m\n\u001b[32m      4\u001b[39m alpha = \u001b[32m0.95\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[32m      7\u001b[39m         \u001b[38;5;28menumerate\u001b[39m(train_loader), total=\u001b[38;5;28mlen\u001b[39m(train_loader), desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m     ):\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m epoch * \u001b[38;5;28mlen\u001b[39m(train_loader) + step == \u001b[32m800\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "loss_acc = 0\n",
    "alpha = 0.95\n",
    "for epoch in tqdm(range(1)):\n",
    "    for step, batch in tqdm(\n",
    "        enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "    ):\n",
    "        if epoch * len(train_loader) + step == 800:\n",
    "            for param in model.base_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        batch = send_inputs_to_device(batch, device)\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = model(**batch)[:2]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Loss moving average\n",
    "        loss_acc = (\n",
    "            loss.item() if step == 0 else loss_acc * alpha + loss.item() * (1 - alpha)\n",
    "        )\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            evaluate(model, dev_loader, device)\n",
    "\n",
    "    model.save_pretrained(f\"/models/working/checkpoints/epoch{epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ 10. Curva ROC e Threshold Ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import torch.nn.functional as F\n",
    "import plotly.express as px\n",
    "\n",
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dev_loader:\n",
    "        batch = send_inputs_to_device(batch, device)\n",
    "        _, scores = model(**batch)[:2]\n",
    "        probs = F.softmax(scores, dim=1)[:, 1]\n",
    "        preds.append(probs.cpu())\n",
    "        true_labels.append(batch[\"labels\"].cpu())\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "true_labels = torch.cat(true_labels).numpy()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(true_labels, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "px.scatter(x=fpr, y=tpr, color=thresholds, title=\"Curva ROC\").show()\n",
    "\n",
    "accuracies = [metrics.accuracy_score(preds > th, true_labels) for th in thresholds]\n",
    "px.scatter(x=thresholds, y=accuracies, title=\"Acur√°cia por Threshold\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ 11. Avalia√ß√£o Final no Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    for batch in test_loader:\n",
    "        batch = send_inputs_to_device(batch, device)\n",
    "        _, scores = model(**batch)[:2]\n",
    "        probs = F.softmax(scores, dim=1)[:, 1]\n",
    "        preds.append(probs.cpu())\n",
    "        true_labels.append(batch[\"labels\"].cpu())\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "true_labels = torch.cat(true_labels).numpy()\n",
    "\n",
    "# Usando o melhor threshold encontrado\n",
    "final_acc = metrics.accuracy_score(preds > 0.67, true_labels)\n",
    "print(f\"Acur√°cia no Teste: {final_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclus√£o\n",
    "\n",
    "Neste tutorial, mostramos como aplicar o BERT para an√°lise de sentimentos em portugu√™s:\n",
    "\n",
    "* Usamos o modelo `neuralmind/bert-base-portuguese-cased`\n",
    "* Processamos e tokenizamos os dados\n",
    "* Treinamos o modelo com congelamento inicial\n",
    "* Avaliamos e otimizamos o threshold via curva ROC\n",
    "\n",
    "Essa abordagem pode ser adaptada para outras tarefas de NLP em portugu√™s. Experimente com datasets diferentes!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
