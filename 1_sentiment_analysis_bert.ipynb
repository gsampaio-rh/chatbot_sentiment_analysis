{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 Tutorial: Análise de Sentimentos em Português com BERT\n",
    "\n",
    "Neste tutorial, vamos aprender como usar o modelo BERT para prever o **sentimento (positivo ou negativo)** de comentários em português no IMDB.\n",
    "\n",
    "Utilizaremos o modelo **BERT pré-treinado da Hugging Face** (`neuralmind/bert-base-portuguese-cased`) e faremos o fine-tuning com PyTorch.\n",
    "\n",
    "## 📌 1. O que é o BERT?\n",
    "\n",
    "O **BERT** (Bidirectional Encoder Representations from Transformers) é um modelo baseado em Transformers, ideal para tarefas de NLP como classificação de texto, análise de sentimentos, entre outros.\n",
    "\n",
    "Neste caso, usamos o **encoder** do BERT para classificar frases como **positivas** ou **negativas**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.env/lib/python3.11/site-packages (2.7.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: transformers in ./.env/lib/python3.11/site-packages (4.53.0)\n",
      "Requirement already satisfied: datasets in ./.env/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./.env/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in ./.env/lib/python3.11/site-packages (2.3.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.2.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tqdm in ./.env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.env/lib/python3.11/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.env/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in ./.env/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.env/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.env/lib/python3.11/site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.env/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.env/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.env/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.env/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.env/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.env/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.env/lib/python3.11/site-packages (from plotly) (1.45.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.env/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.env/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.11/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Downloading torchvision-0.22.1-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.7.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-6.2.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: plotly, torchvision, torchaudio\n",
      "Successfully installed plotly-6.2.0 torchaudio-2.7.1 torchvision-0.22.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio \\\n",
    "    transformers datasets scikit-learn pandas plotly \\\n",
    "    tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade jupyter ipywidgets\n",
    "%jupyter nbextension enable --py widgetsnbextension # removed !pip on the recommendation of a comment.\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "for i in tqdm(range(10)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 2. Carregando os Dados\n",
    "\n",
    "Vamos usar um dataset com resenhas do IMDB traduzidas para português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_en  \\\n",
       "id                                                      \n",
       "1   Once again Mr. Costner has dragged out a movie...   \n",
       "2   This is an example of why the majority of acti...   \n",
       "3   First of all I hate those moronic rappers, who...   \n",
       "4   Not even the Beatles could write songs everyon...   \n",
       "5   Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                              text_pt sentiment  \n",
       "id                                                               \n",
       "1   Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "2   Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "3   Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "4   Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "5   Filmes de fotos de latão não é uma palavra apr...       neg  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega o dataset\n",
    "data = pd.read_csv(\"dataset/imdb-reviews-pt-br.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Estrutura do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49459 entries, 1 to 49460\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text_en    49459 non-null  object\n",
      " 1   text_pt    49459 non-null  object\n",
      " 2   sentiment  49459 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 3 colunas:\n",
    "\n",
    "* `text_en`: texto original em inglês\n",
    "* `text_pt`: texto traduzido para português\n",
    "* `sentiment`: rótulo de sentimento (`pos` ou `neg`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 3. Explorando a Distribuição de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts().plot.pie(autopct=\"%.2f\", explode=[0.01, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset está **balanceado**, então podemos usar **acurácia** como métrica principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 4. Dividindo os Dados\n",
    "\n",
    "Vamos criar conjuntos de treino, validação (dev) e teste na proporção 90/5/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_dev_size = int(0.05 * len(data))\n",
    "train_dev, test = train_test_split(\n",
    "    data, test_size=test_dev_size, stratify=data[\"sentiment\"], random_state=42\n",
    ")\n",
    "train, dev = train_test_split(\n",
    "    train_dev, test_size=test_dev_size, stratify=train_dev[\"sentiment\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔁 5. Preparando o Dataset para o BERT\n",
    "\n",
    "Criamos uma classe para tokenizar e estruturar os dados conforme esperado pelo BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImdbPt(Dataset):\n",
    "    def __init__(self, tokenizer, X, y):\n",
    "        tokenized = tokenizer(list(X), truncation=True, max_length=512)\n",
    "        self.samples = [\n",
    "            {**{k: tokenized[k][i] for k in tokenized}, \"labels\": y.iloc[i]}\n",
    "            for i in range(len(X))\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.samples[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧼 6. Tokenizando e Criando Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x32168f100>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gsampaio/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/gsampaio/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "\n",
    "train_dataset = ImdbPt(\n",
    "    tokenizer, train[\"text_pt\"], (train[\"sentiment\"] == \"pos\").astype(int)\n",
    ")\n",
    "dev_dataset = ImdbPt(tokenizer, dev[\"text_pt\"], (dev[\"sentiment\"] == \"pos\").astype(int))\n",
    "test_dataset = ImdbPt(\n",
    "    tokenizer, test[\"text_pt\"], (test[\"sentiment\"] == \"pos\").astype(int)\n",
    ")\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=collator)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=16, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ 7. Carregando o Modelo e Configurando o Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"neuralmind/bert-base-portuguese-cased\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Congelando o BERT no início\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 8. Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_inputs_to_device(inputs, device):\n",
    "    return {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    tp = tn = fp = fn = 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = send_inputs_to_device(batch, device)\n",
    "            loss, scores = model(**batch)[:2]\n",
    "            losses.append(loss.item())\n",
    "            pred = scores.argmax(dim=1)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            tp += ((pred == 1) & (labels == 1)).sum().item()\n",
    "            tn += ((pred == 0) & (labels == 0)).sum().item()\n",
    "            fp += ((pred == 1) & (labels == 0)).sum().item()\n",
    "            fn += ((pred == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\n",
    "        f\"Dev loss: {sum(losses)/len(losses):.2f}; Acc: {acc:.2f}; tp: {tp}; tn: {tn}; fp: {fp}; fn: {fn}\"\n",
    "    )\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 9. Treinando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m loss_acc = \u001b[32m0\u001b[39m\n\u001b[32m      4\u001b[39m alpha = \u001b[32m0.95\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[32m      7\u001b[39m         \u001b[38;5;28menumerate\u001b[39m(train_loader), total=\u001b[38;5;28mlen\u001b[39m(train_loader), desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m     ):\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m epoch * \u001b[38;5;28mlen\u001b[39m(train_loader) + step == \u001b[32m800\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/redhat/ai/chatbot_sentiment_analysis/.env/lib/python3.11/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "loss_acc = 0\n",
    "alpha = 0.95\n",
    "for epoch in tqdm(range(1)):\n",
    "    for step, batch in tqdm(\n",
    "        enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "    ):\n",
    "        if epoch * len(train_loader) + step == 800:\n",
    "            for param in model.base_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        batch = send_inputs_to_device(batch, device)\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = model(**batch)[:2]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Loss moving average\n",
    "        loss_acc = (\n",
    "            loss.item() if step == 0 else loss_acc * alpha + loss.item() * (1 - alpha)\n",
    "        )\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            evaluate(model, dev_loader, device)\n",
    "\n",
    "    model.save_pretrained(f\"/models/working/checkpoints/epoch{epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📉 10. Curva ROC e Threshold Ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import torch.nn.functional as F\n",
    "import plotly.express as px\n",
    "\n",
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dev_loader:\n",
    "        batch = send_inputs_to_device(batch, device)\n",
    "        _, scores = model(**batch)[:2]\n",
    "        probs = F.softmax(scores, dim=1)[:, 1]\n",
    "        preds.append(probs.cpu())\n",
    "        true_labels.append(batch[\"labels\"].cpu())\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "true_labels = torch.cat(true_labels).numpy()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(true_labels, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "px.scatter(x=fpr, y=tpr, color=thresholds, title=\"Curva ROC\").show()\n",
    "\n",
    "accuracies = [metrics.accuracy_score(preds > th, true_labels) for th in thresholds]\n",
    "px.scatter(x=thresholds, y=accuracies, title=\"Acurácia por Threshold\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧾 11. Avaliação Final no Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    for batch in test_loader:\n",
    "        batch = send_inputs_to_device(batch, device)\n",
    "        _, scores = model(**batch)[:2]\n",
    "        probs = F.softmax(scores, dim=1)[:, 1]\n",
    "        preds.append(probs.cpu())\n",
    "        true_labels.append(batch[\"labels\"].cpu())\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "true_labels = torch.cat(true_labels).numpy()\n",
    "\n",
    "# Usando o melhor threshold encontrado\n",
    "final_acc = metrics.accuracy_score(preds > 0.67, true_labels)\n",
    "print(f\"Acurácia no Teste: {final_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Conclusão\n",
    "\n",
    "Neste tutorial, mostramos como aplicar o BERT para análise de sentimentos em português:\n",
    "\n",
    "* Usamos o modelo `neuralmind/bert-base-portuguese-cased`\n",
    "* Processamos e tokenizamos os dados\n",
    "* Treinamos o modelo com congelamento inicial\n",
    "* Avaliamos e otimizamos o threshold via curva ROC\n",
    "\n",
    "Essa abordagem pode ser adaptada para outras tarefas de NLP em português. Experimente com datasets diferentes!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
